{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rational-advocacy",
   "metadata": {},
   "source": [
    "## Import Important Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "creative-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import os\n",
    "\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-oxford",
   "metadata": {},
   "source": [
    "## Dataframe detail informations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vital-champagne",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Just uncomment and run the program the code to view the details required\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('data_100000.csv')\n",
    "\n",
    "# df.head()           # view the dataframe\n",
    "# df.info()           # view the columns data types and row nan details\n",
    "# df.describe()       # view the dataframe mean, count, std, and other statics\n",
    "# df.dtypes           # view the columns data types\n",
    "# df.columns          # view the name of every avaliable dataframe column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "descending-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8035\n",
      "8035\n",
      "35034\n"
     ]
    }
   ],
   "source": [
    "print(df.latitude.isnull().sum())\n",
    "print(df.longitude.isnull().sum())\n",
    "print(df.zip_code.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-wrapping",
   "metadata": {},
   "source": [
    "## Address to Longtitude and Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bigger-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_long(address):\n",
    "    \n",
    "    # GeoPy to get longtitude and latitude \n",
    "    geolocator = Nominatim(user_agent=\"Address_GeoLocator\")\n",
    "    location = geolocator.geocode(address)\n",
    "    lat_long = [location.latitude, location.longitude]\n",
    "    return lat_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-marble",
   "metadata": {},
   "source": [
    "## Longtitude and Latitude to Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "treated-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_address(latitude, longitude):\n",
    "    \n",
    "    # GeoPy to get addresses \n",
    "    geolocator = Nominatim(user_agent=\"Geo_AddressLocator\")\n",
    "    geo_code = geolocator.reverse(f\"{str(latitude)}, {str(longitude)}\")\n",
    "    adrs = geo_code.raw\n",
    "    adrs = adrs['address']\n",
    "    return adrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "romantic-lying",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_date</th>\n",
       "      <th>crash_time</th>\n",
       "      <th>borough</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "      <th>on_street_name</th>\n",
       "      <th>off_street_name</th>\n",
       "      <th>cross_street_name</th>\n",
       "      <th>...</th>\n",
       "      <th>contributing_factor_vehicle_2</th>\n",
       "      <th>contributing_factor_vehicle_3</th>\n",
       "      <th>contributing_factor_vehicle_4</th>\n",
       "      <th>contributing_factor_vehicle_5</th>\n",
       "      <th>collision_id</th>\n",
       "      <th>vehicle_type_code1</th>\n",
       "      <th>vehicle_type_code2</th>\n",
       "      <th>vehicle_type_code_3</th>\n",
       "      <th>vehicle_type_code_4</th>\n",
       "      <th>vehicle_type_code_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-06T00:00:00.000</td>\n",
       "      <td>13:00</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472.0</td>\n",
       "      <td>40.829052</td>\n",
       "      <td>-73.85038</td>\n",
       "      <td>(40.829052, -73.85038)</td>\n",
       "      <td>CASTLE HILL AVENUE</td>\n",
       "      <td>BLACKROCK AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3665311</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                crash_date crash_time borough  zip_code   latitude  longitude  \\\n",
       "1  2017-05-06T00:00:00.000      13:00   BRONX   10472.0  40.829052  -73.85038   \n",
       "\n",
       "                 location                    on_street_name   off_street_name  \\\n",
       "1  (40.829052, -73.85038)  CASTLE HILL AVENUE                BLACKROCK AVENUE   \n",
       "\n",
       "  cross_street_name  ...  contributing_factor_vehicle_2  \\\n",
       "1               NaN  ...                            NaN   \n",
       "\n",
       "   contributing_factor_vehicle_3  contributing_factor_vehicle_4  \\\n",
       "1                            NaN                            NaN   \n",
       "\n",
       "   contributing_factor_vehicle_5  collision_id  vehicle_type_code1  \\\n",
       "1                            NaN       3665311               Sedan   \n",
       "\n",
       "   vehicle_type_code2  vehicle_type_code_3 vehicle_type_code_4  \\\n",
       "1                 NaN                  NaN                 NaN   \n",
       "\n",
       "  vehicle_type_code_5  \n",
       "1                 NaN  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.on_street_name.notnull()].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-stability",
   "metadata": {},
   "source": [
    "## Fill null value of \n",
    "---\n",
    "* zip_code\n",
    "* borough\n",
    "* on_street_name\n",
    "\n",
    "using \"latitude\" and \"longitude\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-advertising",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total null values 25179\n"
     ]
    }
   ],
   "source": [
    "geo_list = df[(df.latitude.notnull()) & (df.on_street_name.isnull())].index.tolist()\n",
    "\n",
    "per_loop_data = 50\n",
    "total_loop = int((len(geo_list)/per_loop_data)+1)\n",
    "\n",
    "error_limit = 0  \n",
    "\n",
    "print(\"Total null values\", len(geo_list))\n",
    "\n",
    "while True:\n",
    "    for attempt in range(total_loop):\n",
    "        \n",
    "        try:\n",
    "            geo_list = df[(df.latitude.notnull()) & (df.longitude.notnull()) & (df.on_street_name.isnull())].index.tolist()\n",
    "            for ind in geo_list[:per_loop_data]:\n",
    "                lat = df.latitude[df.index == ind].values[0]\n",
    "                lon = df.longitude[df.index == ind].values[0]\n",
    "\n",
    "                adrs = reverse_address(lat, lon)\n",
    "\n",
    "                try:\n",
    "                    zip_code = adrs['postcode']\n",
    "                except:\n",
    "                    zip_code = None\n",
    "                \n",
    "                try:\n",
    "                    bor = adrs[\"suburb\"]\n",
    "                except:\n",
    "                    zip_code = None\n",
    "                \n",
    "                try:\n",
    "                    street = adrs['road']\n",
    "                except:\n",
    "                    zip_code = None\n",
    "\n",
    "                df.loc[ind,\"zip_code\"] = zip_code\n",
    "                df.loc[ind,\"borough\"] = bor\n",
    "                df.loc[ind,\"on_street_name\"] = street\n",
    "                error_limit = 0\n",
    "        \n",
    "        except Exception as e: \n",
    "            error_limit += 1\n",
    "            if error_limit > 5:\n",
    "                break\n",
    "            \n",
    "            print(e)\n",
    "            print(\"Error!! Re-attempt\")\n",
    "            print(len(geo_list))\n",
    "            \n",
    "            time.sleep(3)\n",
    "            \n",
    "            \n",
    "        if len(geo_list) == 0 or error_limit > 5:\n",
    "            break\n",
    "    \n",
    "print(\"End of the process\", len(geo_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "orange-maldives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apples erer ther\n",
      "banan erer applesr\n"
     ]
    }
   ],
   "source": [
    "txt = \"banan erer ther\"\n",
    "\n",
    "x = txt.replace(\"banan\", \"apples\")\n",
    "y = txt.replace(\"the\", \"apples\")\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-latter",
   "metadata": {},
   "source": [
    "## Fill null value of \n",
    "---\n",
    "* latitude\n",
    "* longitude\n",
    "\n",
    "using \"zip_code\" and \"borough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-halloween",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zip_list = df[(df.latitude.isnull()) & (df.zip_code.notnull())].index.tolist()\n",
    "per_loop_data = 25\n",
    "total_loop = int((len(zip_list)/per_loop_data)+1)\n",
    "\n",
    "error_limit = 0   # if limi the loop to analysis the error\n",
    "\n",
    "print(\"Total null values\", len(zip_list))\n",
    "\n",
    "while True:\n",
    "    for attempt in range(total_loop):\n",
    "        \n",
    "        try:\n",
    "            zip_list = df[(df.latitude.isnull()) & (df.zip_code.notnull())].index.tolist()\n",
    "            for ind in zip_list[:per_loop_data]:\n",
    "                bor = df.borough[df.index == ind].values\n",
    "                zip_code = df.zip_code[df.index == ind].values\n",
    "                codi = lat_long(f\"{zip_code} {bor} NYC\")\n",
    "                df.loc[ind,\"latitude\"] = codi[0]\n",
    "                df.loc[ind,\"longitude\"] = codi[1]\n",
    "                error_limit = 0\n",
    "                \n",
    "        except Exception as e: \n",
    "            error_limit += 1\n",
    "            if error_limit > 5:\n",
    "                break\n",
    "                \n",
    "            print(e)\n",
    "            print(\"Error!! Re-attempt\")\n",
    "            print(len(zip_list))\n",
    "            time.sleep(3)\n",
    "            \n",
    "    \n",
    "    if len(zip_list) == 0 or error_limit > 5:\n",
    "        break\n",
    "    \n",
    "print(\"End of the process\", len(zip_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling null value of address consume lot s time and memory so save address into new dire to work fresh.\n",
    "\n",
    "if not os.path.exists(\"data_files\"):\n",
    "    os.makedirs(\"data_files\")\n",
    "df.to_csv(r'./data_files/filling_missing_address.csv', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.latitude.isnull().sum())\n",
    "print(df.longitude.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-filename",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'./data_files/filling_missing_address.csv')\n",
    "\n",
    "\"\"\"\n",
    "combin the date and time and convert data\n",
    "type to date type to short accident base \n",
    "on time period\n",
    "\"\"\"\n",
    "df[[\"period\"]] = (df[\"crash_date\"] + ' ' + df[\"crash_time\"])  # combine date and time\n",
    "df.period = df.period.astype('datetime64[ns]')                # convert column to datetime \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "convert the \"crash_date\" to \"datetime\" data \n",
    "type to futher break data and find futher \n",
    "feature like date, data, month\n",
    "\"\"\"\n",
    "df[\"crash_date\"] = df[\"crash_date\"].astype('datetime64[ns]')  # convert colum to date time format\n",
    "df[\"year\"] = df[\"crash_date\"].dt.year                         # get the year\n",
    "df[\"month\"] = df[\"crash_date\"].dt.month                       # get the month\n",
    "df[\"day\"] = df[\"crash_date\"].dt.day                           # get the day\n",
    "df[\"weekday\"] = df[\"crash_date\"].dt.weekday                   # figure out which day it was\n",
    "df[\"hour\"] = pd.to_datetime(df['crash_time'], format='%H:%M').dt.hour  # grabing just hour value\n",
    "\n",
    "\"\"\"\n",
    "Based on the week days find accident happen\n",
    "on weekday or on weekend.\n",
    "\"\"\"\n",
    "df[\"day_status\"] = 0                               # \"weekday\"\n",
    "df[\"day_status\"].loc[df['weekday'] >4] = 1         # \"weekend\"\n",
    "\n",
    "\"\"\"\n",
    "Based on the month information finding \n",
    "at what session more safty needs to be concern.\n",
    "\"\"\"\n",
    "df[\"month_status\"] = 0                                                      # \"fall\"\n",
    "df.loc[(df[\"month\"] < 3) | (df[\"month\"] >= 12), \"month_status\"] = 1         # \"winter\"\n",
    "df.loc[(df[\"month\"] < 6) & (df[\"month\"] >= 3), \"month_status\"] = 2         # \"spring\"\n",
    "df.loc[(df[\"month\"] < 9) & (df[\"month\"] >= 6), \"month_status\"] = 3         # \"summer\"\n",
    "\n",
    "\"\"\"\n",
    "Based on the hour and weekday or weekenday \n",
    "finding what high accident chance day and hour.\n",
    "\"\"\"\n",
    "df[\"hour_status\"] = 0                                                                  # \"Evening\"\n",
    "df.loc[(df[\"hour\"] < 18) & (df[\"day_status\"] == \"weekday\"), \"hour_status\"] = 1         # \"working_hour\"\n",
    "df.loc[(df[\"hour\"] < 7) & (df[\"day_status\"] == \"weekday\"), \"hour_status\"] = 2          # \"night\"\n",
    "df.loc[(df[\"hour\"] < 16) & (df[\"day_status\"] == \"weekday\"), \"hour_status\"] = 3         # \"day\"\n",
    "df.loc[(df[\"hour\"] < 7) & (df[\"day_status\"] == \"weekday\"), \"hour_status\"] = 4          # \"night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding total number of accident victim per row.\n",
    "df[\"total_victim\"] = df.number_of_persons_injured + df.number_of_persons_killed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-haven",
   "metadata": {},
   "source": [
    "##  Null values graphical presentatin and understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-librarian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Drop the column where missing value is above 10% else just remove row')\n",
    "print('Data size:', df.shape[0])\n",
    "print('Data limit: ',int(0.1* df.shape[0]))\n",
    "\n",
    "sn.heatmap(df.isnull(), yticklabels= False, cbar= False, cmap= 'Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-float",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum() # viwe rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data on these columns are very incorrent mistpyes plus similar columns were missing lots of data\n",
    "# df = df.drop(columns=['vehicle_type_code1','contributing_factor_vehicle_1'])\n",
    "\n",
    "# Replace 'nan' to 'Unspecified'\n",
    "df[\"contributing_factor_vehicle_1\"] = df[\"contributing_factor_vehicle_1\"].fillna('Unspecified')\n",
    "\n",
    "# Replace 'nan' to 'Unknown'\n",
    "df[\"vehicle_type_code1\"] = df[\"vehicle_type_code1\"].fillna('Unknown')\n",
    "\n",
    "# create heave light small etc catagory . 2 wheller or not.\n",
    "t = df[\"vehicle_type_code1\"].unique().tolist()\n",
    "t.sort()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-footwear",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print()\n",
    "    print(f\"********** {i} **********\")\n",
    "    print(df[f'{i}'].unique())\n",
    "    print(df[f'{i}'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-homework",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-pocket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-hearing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After attemping to get most of null values and extra values drop any columns that exceed the 10% null limit\n",
    "\n",
    "drop_col = [\"crash_date\", \"crash_time\", \"location\"]\n",
    "\n",
    "null_limit = 0.1\n",
    "for i in df.columns:\n",
    "    if df[f'{i}'].isna().sum() >=  int(null_limit * df.shape[0]):\n",
    "        drop_col.append(i)\n",
    "        \n",
    "df = df.drop(columns=drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-dominican",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cheeck if there are any dublicate rows\n",
    "duplicate = df[df.duplicated()] \n",
    "print(\"Duplicate Rows :\") \n",
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()  # or 'nan' is '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-scheme",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['period','latitude', 'longitude', 'number_of_persons_injured',\n",
    "       'number_of_persons_killed', 'number_of_pedestrians_injured',\n",
    "       'number_of_pedestrians_killed', 'number_of_cyclist_injured',\n",
    "       'number_of_cyclist_killed', 'number_of_motorist_injured',\n",
    "       'number_of_motorist_killed', 'collision_id', 'year', 'month',\n",
    "       'day', 'weekday', 'hour', 'day_status', 'month_status', 'hour_status',\n",
    "       'total_victim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['period'])\n",
    "df = df.reset_index()\n",
    "df = df.drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_headers = df.columns\n",
    "dataset2 = df\n",
    "feature_col = dataset2.shape[1]\n",
    "plt_col = 2\n",
    "plt_row = int((len(column_headers)/plt_col) + 1)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 25))\n",
    "plt.suptitle('Subtitle for diagram', fontsize=20)\n",
    "for i in range(feature_col):\n",
    "    plt.subplot(plt_row, plt_col, i + 1)\n",
    "    f = plt.gca()\n",
    "    f.set_title(dataset2.columns.values[i])\n",
    "    vals = np.size(dataset2.iloc[:, i].unique())\n",
    "    \n",
    "    # This help ploting process easier\n",
    "    if vals >= 100:\n",
    "        vals = 100\n",
    "    \n",
    "    plt.hist(dataset2.iloc[:, i], bins=vals, color='#3F5D7D')\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.set_tight_layout(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-moral",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Correlation every feature\n",
    "corr = df.corr()\n",
    "sn.set(font_scale=2.8)\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize = (50,40))\n",
    "sn.heatmap(corr, annot=True,mask=mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation with independent variable (Note: Models like RF are not linear like these)\n",
    "\n",
    "fig = \"number_of_motorist_killed\"\n",
    "df.corrwith(df[f\"{fig}\"]).plot.bar(figsize = (20, 10), \n",
    "                                                        title = f\"{fig}\",\n",
    "                                                        fontsize = 15,\n",
    "                                                        rot = 45, grid = True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
